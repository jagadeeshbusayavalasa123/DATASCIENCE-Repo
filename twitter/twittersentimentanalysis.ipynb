{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74967017-5773-4694-b13b-e44bd23014c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas scikit-learn nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0537f6c-c85c-4aae-9349-6efd347b4b71",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [WinError 10060] A\n",
      "[nltk_data]     connection attempt failed because the connected party\n",
      "[nltk_data]     did not properly respond after a period of time, or\n",
      "[nltk_data]     established connection failed because connected host\n",
      "[nltk_data]     has failed to respond>\n",
      "[nltk_data] Error loading punkt: <urlopen error [WinError 10060] A\n",
      "[nltk_data]     connection attempt failed because the connected party\n",
      "[nltk_data]     did not properly respond after a period of time, or\n",
      "[nltk_data]     established connection failed because connected host\n",
      "[nltk_data]     has failed to respond>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97866e34-d98a-44c8-a561-f6dfb8a1b4f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "#from sklearn.externals import joblib\n",
    "import pickle\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88074c07-c35c-452a-bb9e-47d78d24e4e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load your Twitter sentiment dataset in CSV format\n",
    "# Assuming your CSV file has two columns: 'text' and 'label'\n",
    "df = pd.read_csv(r\"F:\\GUVI\\twitter_new.csv\",encoding='ISO-8859-1',names=['label','b','c','d','e','text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5593e846-1583-47cd-943c-81b6e257ba02",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          switchfoot http twitpic com 2y1zl awww bummer ...\n",
       "1          upset updat facebook text might cri result sch...\n",
       "2          kenichan dive mani time ball manag save 50 res...\n",
       "3                            whole bodi feel itchi like fire\n",
       "4                              nationwideclass behav mad see\n",
       "                                 ...                        \n",
       "1599995                           woke school best feel ever\n",
       "1599996    thewdb com cool hear old walt interview â http...\n",
       "1599997                         readi mojo makeov ask detail\n",
       "1599998    happi 38th birthday boo alll time tupac amaru ...\n",
       "1599999    happi charitytuesday thenspcc sparkschar speak...\n",
       "Name: text, Length: 1600000, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocess the data\n",
    "stop_words = set(stopwords.words('english'))\n",
    "ps = PorterStemmer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "    words=tokenizer.tokenize(text)\n",
    "    #words = word_tokenize(text)\n",
    "    words = [ps.stem(word) for word in words if word.isalnum() and word.lower() not in stop_words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "df['text'] = df['text'].apply(preprocess_text)\n",
    "\n",
    "df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9dd67f6-ab03-4184-a569-045f221d9345",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_digit(x):\n",
    "    x = x.split()\n",
    "    for t in range(0,len(x)):\n",
    "        if(x[t].isdigit()):\n",
    "            x[t] = ''\n",
    "    return ' '.join(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2211b0f1-5583-4be8-855b-ba6ea2e9ed2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3befd6ed-9c12-4c6b-b4a7-3fa56734a48a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(lambda x : remove_digit(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e4a5b88-4c12-492e-9c27-7a07cbc8b55c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(lambda x : str(x).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4498c488-d068-4b51-947c-2e6a66fa7f43",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>switchfoot http twitpic com 2y1zl awww bummer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>upset updat facebook text might cri result sch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>kenichan dive mani time ball manag save  rest ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>whole bodi feel itchi like fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>nationwideclass behav mad see</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601966</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>AmandaMarie1028</td>\n",
       "      <td>woke school best feel ever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601969</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>TheWDBoards</td>\n",
       "      <td>thewdb com cool hear old walt interview â http...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601991</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>bpbabe</td>\n",
       "      <td>readi mojo makeov ask detail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>4</td>\n",
       "      <td>2193602064</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>tinydiamondz</td>\n",
       "      <td>happi 38th birthday boo alll time tupac amaru ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599999</th>\n",
       "      <td>4</td>\n",
       "      <td>2193602129</td>\n",
       "      <td>Tue Jun 16 08:40:50 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>RyanTrevMorris</td>\n",
       "      <td>happi charitytuesday thenspcc sparkschar speak...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         label           b                             c         d  \\\n",
       "0            0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1            0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2            0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3            0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4            0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "...        ...         ...                           ...       ...   \n",
       "1599995      4  2193601966  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599996      4  2193601969  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599997      4  2193601991  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599998      4  2193602064  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599999      4  2193602129  Tue Jun 16 08:40:50 PDT 2009  NO_QUERY   \n",
       "\n",
       "                       e                                               text  \n",
       "0        _TheSpecialOne_  switchfoot http twitpic com 2y1zl awww bummer ...  \n",
       "1          scotthamilton  upset updat facebook text might cri result sch...  \n",
       "2               mattycus  kenichan dive mani time ball manag save  rest ...  \n",
       "3                ElleCTF                    whole bodi feel itchi like fire  \n",
       "4                 Karoli                      nationwideclass behav mad see  \n",
       "...                  ...                                                ...  \n",
       "1599995  AmandaMarie1028                         woke school best feel ever  \n",
       "1599996      TheWDBoards  thewdb com cool hear old walt interview â http...  \n",
       "1599997           bpbabe                       readi mojo makeov ask detail  \n",
       "1599998     tinydiamondz  happi 38th birthday boo alll time tupac amaru ...  \n",
       "1599999   RyanTrevMorris  happi charitytuesday thenspcc sparkschar speak...  \n",
       "\n",
       "[1600000 rows x 6 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e414f2db-2a3f-4226-b8f2-903adb8dc54a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X=df['text']\n",
    "y=df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8ab4e1d9-190b-4891-89e7-c9dfe48dd8ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Vectorize the text data using TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=None, stop_words='english')\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Vectorize the text data using TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=None, stop_words='english')\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e674865-926c-476f-8397-9adbcc12e778",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.77\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.75      0.77    159494\n",
      "           4       0.76      0.80      0.78    160506\n",
      "\n",
      "    accuracy                           0.77    320000\n",
      "   macro avg       0.78      0.77      0.77    320000\n",
      "weighted avg       0.78      0.77      0.77    320000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train different machine learning models\n",
    "models = {\n",
    "    'MultinomialNB': MultinomialNB(),\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=2, random_state=42),\n",
    "    'Support Vector Machine': SVC()\n",
    "}\n",
    "model=LogisticRegression()\n",
    "model.fit(X_train_vectorized, y_train)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "y_pred = model.predict(X_test_vectorized)\n",
    "    \n",
    "    # Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    " \n",
    "#print(f'\\n{model_name} Model:')\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print('Classification Report:')\n",
    "print(report)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c8f85270-0651-455b-b823-7797ee25c8fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'penalty' : ['l1','l2'],\n",
    "    'solver' : ['newton-cg','sag','saga','liblinear'],\n",
    "    'dual' : ['auto',True,False],\n",
    "    'tol' : [0.1,0.01,0.001],\n",
    "    'C' : [1.0,2.0]\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7856c063-1d71-494b-93f3-d1e4a4db07e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gs = GridSearchCV(estimator = LogisticRegression(), param_grid=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbb8da8-08c8-4ed4-9d3b-600d904aed75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gs.fit(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3774fe48-2fcc-421f-923b-2ef526e74142",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c0042d-191b-4215-97b7-7cb751916b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=LogisticRegression()\n",
    "model.fit(X_train_vectorized, y_train)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "y_pred = model.predict(X_test_vectorized)\n",
    "    \n",
    "    # Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    " \n",
    "#print(f'\\n{model_name} Model:')\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print('Classification Report:')\n",
    "print(report)\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
